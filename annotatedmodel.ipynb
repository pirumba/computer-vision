{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "mount_file_id": "17CUkOci7IkRQ8-0FbdQmcVE3mugx3eLV",
      "authorship_tag": "ABX9TyNp2zdy/AcpzFzVs5gQhA5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pirumba/computer-vision/blob/main/annotatedmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XRUe7sBNaWB"
      },
      "outputs": [],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Assemble Our Dataset**\n",
        "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n",
        "\n",
        "In Roboflow, you can choose between two paths:\n",
        "\n",
        "Convert an existing dataset to YOLOv5 format. Roboflow supports over 30 formats object detection formats for conversion.\n",
        "Upload raw images and annotate them in Roboflow with Roboflow Annotate."
      ],
      "metadata": {
        "id": "H44g-rjxOHzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"
      ],
      "metadata": {
        "id": "J4Bq2jhHOA_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up environment\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "YXD-HIIFOUp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #after following the link above, recieve python code with these fields filled in\n",
        "# #from roboflow import Roboflow\n",
        "# #rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n",
        "# #project = rf.workspace().project(\"YOUR PROJECT\")\n",
        "# #dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")\n",
        "# # !pip install roboflow\n",
        "\n",
        "# # from roboflow import Roboflow\n",
        "# # rf = Roboflow(api_key=\"Ij15bccaCSFhYVqlPkTR\")\n",
        "# # project = rf.workspace().project(\"cropdetection-no4dz\")\n",
        "# # dataset = project.version(1).download(\"yolov5\")\n",
        "\n",
        "# # # \n",
        "\n",
        "# !pip install roboflow\n",
        "\n",
        "# from roboflow import Roboflow\n",
        "# rf = Roboflow(api_key=\"Mwu3QmrQ1Xs3zTjSBiQB\")\n",
        "# project = rf.workspace().project(\"hard-hat-sample-vkfar\")\n",
        "# dataset = project.version(2).download(\"yolov5\")\n",
        "\n",
        "# !pip install roboflow\n",
        "\n",
        "# # from roboflow import Roboflow\n",
        "# # rf = Roboflow(api_key=\"Mwu3QmrQ1Xs3zTjSBiQB\")\n",
        "# # project = rf.workspace(\"\").project(\"hard-hat-sample-vkfar\")\n",
        "# # dataset = project.version(2).download(\"yolov5\")\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Mwu3QmrQ1Xs3zTjSBiQB\")\n",
        "project = rf.workspace().project(\"crops-ifvld\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ],
      "metadata": {
        "id": "2tZ7urLaOeiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iSR34wRZeLET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename = '/content/yolov5/runs/train/exp/val_batch0_pred.jpg', width =1500)"
      ],
      "metadata": {
        "id": "2Tnu1daZOkYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Train Our Custom YOLOv5 model**\n",
        "Here, we are able to pass a number of arguments:\n",
        "\n",
        "img: define input image size\n",
        "batch: determine batch size\n",
        "epochs: define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "data: Our dataset locaiton is saved in the dataset.location\n",
        "weights: specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "cache: cache images for faster training"
      ],
      "metadata": {
        "id": "3_MAWachOwAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 10 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "Y3GariBXOzwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is mAP_0.5 - learn more about mean average precision here."
      ],
      "metadata": {
        "id": "VYM2KhCcPMGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "ZVqq23rSPF7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Inference With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of test/images folder downloaded from Roboflow."
      ],
      "metadata": {
        "id": "Yto6-70DPefJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 190 --conf 0.1 --source {dataset.location}/test/images"
      ],
      "metadata": {
        "id": "Ij_AOMJzPXMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "3icmw117PpsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export your model's weights for future use\n",
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "id": "l8TR229BV7Nc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}